(window.webpackJsonp=window.webpackJsonp||[]).push([[106],{333:function(t,e,a){"use strict";a.r(e);var n=a(28),r=Object(n.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"影像追踪"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#影像追踪"}},[t._v("#")]),t._v(" 影像追踪")]),t._v(" "),a("p",[t._v("图像跟踪可以扫描图片，图形，任何图像并在其上显示内容。")]),t._v(" "),a("p",[t._v("为了简洁起见，以下所有示例均与A框架一起使用。如果需要，可以使用three.js。请参阅官方存储库上的nft three.js示例。")]),t._v(" "),a("p",[t._v("此处提供了所有用于图像跟踪的A帧示例。")]),t._v(" "),a("h2",{attrs:{id:"图像跟踪入门"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#图像跟踪入门"}},[t._v("#")]),t._v(" 图像跟踪入门")]),t._v(" "),a("p",[t._v("自然特征跟踪或NFT是一项技术，可使用图像代替QR码或Hiro标记等标记。")]),t._v(" "),a("p",[t._v("该软件跟踪图像中的有趣点，并使用它们来估计相机的位置。这些有趣的点（也称为“图像描述符”）是使用NFT Marker Creator可创建NFT标记的工具创建的。它有两个版本：Web版本（推荐）和node.js版本。AR.js Github组织中也有这个项目的分支，但是到目前为止，Daniel Fernandes版本可以完美地工作。")]),t._v(" "),a("p",[t._v("感谢Daniel Fernandes在此文档部分中的贡献。")]),t._v(" "),a("h2",{attrs:{id:"选择好的图像"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#选择好的图像"}},[t._v("#")]),t._v(" 选择好的图像")]),t._v(" "),a("p",[t._v("如果您想更深入地了解标记的创建，请查看NFT标记创建者Wiki。它也解释了为什么某些图像比其他图像效果更好。一个重要的因素是图像的DPI：良好的dpi（300或更高）将提供很好的稳定性，而低DPI（例如72）将要求用户保持非常静止并靠近图像，否则跟踪会滞后。")]),t._v(" "),a("h2",{attrs:{id:"创建图像描述符"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#创建图像描述符"}},[t._v("#")]),t._v(" 创建图像描述符")]),t._v(" "),a("p",[t._v("选择图像后，可以在其Web版本或节点版本中使用NFT Marker Creator 。")]),t._v(" "),a("p",[t._v("如果您使用的是节点版本，这是运行的基本命令：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("node app.js -i <path-to-the-img/image-name.jpg/png>\n")])])]),a("p",[t._v("之后，您将在output文件夹中找到“图像描述符” 文件。在网络版本中，生成器将自动从浏览器下载文件。")]),t._v(" "),a("p",[t._v("在这两种情况下，你将最终获得三个文件的图像描述符，用.fset，.fset3，.iset。每个文件扩展名前都有相同的前缀。那就是您将在AR.js Web应用程序上使用的图像描述符名称。例如：与文件trex.fset，trex.fset3和trex.iset，你的图像描述符的名字将出现trex。")]),t._v(" "),a("h2",{attrs:{id:"呈现内容"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#呈现内容"}},[t._v("#")]),t._v(" 呈现内容")]),t._v(" "),a("p",[t._v("现在是时候创建实际的AR Web应用程序了。")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('\x3c!-- import aframe and then ar.js with image tracking / location based features --\x3e\n<script src="https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js"><\/script>\n<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"><\/script>\n\n\x3c!-- style for the loader --\x3e\n<style>\n  .arjs-loader {\n    height: 100%;\n    width: 100%;\n    position: absolute;\n    top: 0;\n    left: 0;\n    background-color: rgba(0, 0, 0, 0.8);\n    z-index: 9999;\n    display: flex;\n    justify-content: center;\n    align-items: center;\n  }\n\n  .arjs-loader div {\n    text-align: center;\n    font-size: 1.25em;\n    color: white;\n  }\n</style>\n\n<body style="margin : 0px; overflow: hidden;">\n  \x3c!-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power --\x3e\n  <div class="arjs-loader">\n    <div>Loading, please wait...</div>\n  </div>\n\n  \x3c!-- a-frame scene --\x3e\n  <a-scene\n    vr-mode-ui="enabled: false;"\n    renderer="logarithmicDepthBuffer: true;"\n    embedded\n    arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;"\n  >\n    \x3c!-- a-nft is the anchor that defines an Image Tracking entity --\x3e\n    \x3c!-- on \'url\' use the path to the Image Descriptors created before. --\x3e\n    \x3c!-- the path should end with the name without the extension e.g. if file is \'pinball.fset\' the path should end with \'pinball\' --\x3e\n    <a-nft\n      type="nft"\n      url="<path-to-your-image-descriptors>"\n      smooth="true"\n      smoothCount="10"\n      smoothTolerance=".01"\n      smoothThreshold="5"\n    >\n        \x3c!-- as a child of the a-nft entity, you can define the content to show. here\'s a GLTF model entity --\x3e\n        <a-entity\n            gltf-model="<path-to-your-model>"\n            scale="5 5 5"\n            position="50 150 0"\n        >\n        </a-entity>\n    </a-nft>\n    \x3c!-- static camera that moves according to the device movemenents --\x3e\n    <a-entity camera></a-entity>\n  </a-scene>\n</body>\n')])])]),a("p",[t._v("有关说明，请参见上面的注释，内联代码。")]),t._v(" "),a("p",[t._v("您可以参考A-Frame文档以了解有关内容和自定义的所有信息。您可以添加几何，3D模型，视频，图像。您可以自定义其位置，比例，旋转度等。")]),t._v(" "),a("p",[t._v("这里唯一的自定义组件是a-nftImage Tracking HTML锚。")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("<a-nft\\>\n\n")])])]),a("p",[t._v("这是该实体的属性")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("属性")]),t._v(" "),a("th",[t._v("描述")]),t._v(" "),a("th",[t._v("组件映射")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("type")]),t._v(" "),a("td",[t._v("标记的类型-[仅'nft'有效值]")]),t._v(" "),a("td",[t._v("artoolkitmarker.type")])]),t._v(" "),a("tr",[a("td",[t._v("url")]),t._v(" "),a("td",[t._v("图片描述符的网址，不带扩展名")]),t._v(" "),a("td",[t._v("artoolkitmarker.descriptorsUrl")])]),t._v(" "),a("tr",[a("td",[t._v("emitevents")]),t._v(" "),a("td",[t._v("发出'markerFound'和'markerLost'事件-['true'，'false']")]),t._v(" "),a("td",[t._v("--")])]),t._v(" "),a("tr",[a("td",[t._v("smooth")]),t._v(" "),a("td",[t._v("打开/关闭相机平滑功能-['true'，'false']-默认值：false")]),t._v(" "),a("td",[t._v("--")])]),t._v(" "),a("tr",[a("td",[t._v("smoothCount")]),t._v(" "),a("td",[t._v("要平滑跟踪的矩阵数，更多=平滑但慢速跟踪-默认值：5")]),t._v(" "),a("td",[t._v("--")])]),t._v(" "),a("tr",[a("td",[t._v("smoothTolerance")]),t._v(" "),a("td",[t._v("平滑的距离公差，如果矩阵的smoothThreshold＃低于公差，跟踪将保持静止-默认值：0.01")]),t._v(" "),a("td",[t._v("--")])]),t._v(" "),a("tr",[a("td",[t._v("smoothThreshold")]),t._v(" "),a("td",[t._v("平滑阈值，除非足够的矩阵超出公差，否则它将保持不变-默认值：2")]),t._v(" "),a("td",[t._v("--")])]),t._v(" "),a("tr",[a("td",[t._v("size")]),t._v(" "),a("td",[t._v("标记的大小（以米为单位）")]),t._v(" "),a("td",[t._v("artoolkitmarker.size")])])])]),t._v(" "),a("p",[t._v("建议使用smooth，smoothCount并且smoothTolerance由于图像跟踪中内容的稳定性较弱。借助平滑功能，内容从3D模型到2D视频都更加稳定。")])])}),[],!1,null,null,null);e.default=r.exports}}]);