(window.webpackJsonp=window.webpackJsonp||[]).push([[112],{309:function(a,t,e){"use strict";e.r(t);var s=e(28),r=Object(s.a)({},(function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h1",{attrs:{id:"ar-js入门"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ar-js入门"}},[a._v("#")]),a._v(" AR.js入门")]),a._v(" "),e("p",[a._v("AR.js是一个用于Web增强现实的轻量级库，具有图像跟踪，基于位置的AR和标记跟踪等功能。")]),a._v(" "),e("h2",{attrs:{id:"web-ar的含义（网络上的增强现实）"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#web-ar的含义（网络上的增强现实）"}},[a._v("#")]),a._v(" Web AR的含义（网络上的增强现实）")]),a._v(" "),e("p",[a._v("增强现实技术使在现实世界中添加叠加内容成为可能。可以为多种类型的设备提供它：手持设备（如手机），耳机，台式机显示器等。")]),a._v(" "),e("p",[a._v("对于手持设备（通常，对于视频透视设备），“真实性”是从一个或多个摄像机捕获的，然后显示在设备显示屏上，并在其顶部添加某种内容。")]),a._v(" "),e("p",[a._v("对于开发人员而言，要在Web上开发增强现实（从现在开始称为“ AR”），意味着使所有移动应用程序开发工作和与应用程序商店相关的成本（验证，发布时间）无效。这也意味着重新使用许多开发人员和可能的设计师所熟知的众所周知的技术，例如Javascript，HTML和CSS。")]),a._v(" "),e("p",[a._v("基本上，这意味着可以立即发布每个新版本，修复错误或几乎实时发布新功能，从而提供了许多实用的可能性。")]),a._v(" "),e("p",[a._v("对于用户而言，这意味着只需访问网站即可获得AR体验。由于QR码现在很普遍，因此也可以扫描QR码并到达URL而无需输入任何内容。令人上瘾的是，用户不必在下载的AR应用程序上保留存储空间，也不必对其进行更新。")]),a._v(" "),e("h2",{attrs:{id:"为什么选择ar-js"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#为什么选择ar-js"}},[a._v("#")]),a._v(" 为什么选择AR.js")]),a._v(" "),e("p",[a._v("我们相信Web是一种协作且可访问的环境。我们还相信增强现实技术作为一种新的交流媒介，可以帮助人们以新颖，令人兴奋的方式看到现实。我们看到增强现实（AR）每天都用于许多有用的应用程序，从艺术到教育，也很有趣。")]),a._v(" "),e("p",[a._v("我们坚信，这种可以帮助人们并利用其创造力的强大技术应该以某种方式免费提供。如果可能，也要合作。因此，我们继续开展由Jerome Etienne开始的工作，将AR作为一种免费的开源技术引入Web。")]),a._v(" "),e("p",[a._v("感谢您对此感兴趣，如果您想以任何方式进行合作，请与我们联系（https://twitter.com/nicolocarp）。")]),a._v(" "),e("p",[a._v("该项目现在由Github组织管理，您可以在https://github.com/ar-js-org上找到该项目，也可以免费要求加入该项目。")]),a._v(" "),e("h3",{attrs:{id:"ar类型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ar类型"}},[a._v("#")]),a._v(" AR类型")]),a._v(" "),e("p",[a._v("AR.js在Web上具有以下类型的增强现实：")]),a._v(" "),e("p",[a._v("图像跟踪，当摄像机找到2D图像时，可以在其顶部或附近显示某种内容。内容也可以是2D图像，GIF，3D模型（也可以动画）和2D视频。使用案例：增强型艺术，学习（增强型书籍），增强型传单，广告等。")]),a._v(" "),e("p",[a._v("基于位置的AR，这种AR使用真实世界的位置来在用户设备上显示增强现实内容。可以使用该库构建的体验是那些使用用户在现实世界中的位置的体验。用户可以移动（理想情况下是室外），并通过智能手机可以看到AR内容在现实世界中的位置。移动和旋转手机将使AR内容根据用户的位置和旋转而发生变化（因此，位置会“固定”在其实际位置上，并根据与用户的距离而变大/变细）。使用此解决方案，可以建立诸如交互式的旅游指南支持，探索新城市时的支持，寻找建筑物，博物馆，饭店，酒店等名胜古迹的体验。")]),a._v(" "),e("p",[a._v("标记跟踪，当照相机找到标记时，可以显示一些内容（与图像跟踪相同）。标记非常稳定，但形状，颜色和大小受到限制。建议针对需要大量不同内容的标记的体验。使用示例：（增强书籍），增强传单，广告。")]),a._v(" "),e("h3",{attrs:{id:"关键点"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#关键点"}},[a._v("#")]),a._v(" 关键点")]),a._v(" "),e("p",[a._v("非常快：即使在手机上也能高效运行\n基于Web的：这是一个纯Web解决方案，因此无需安装。基于three.js + A-Frame + jsartoolkit5的完整javascript\n开源：它是完全开源且免费的！\n标准：可以在任何装有webgl和webrtc的电话上使用\nAR.js已达到版本3。这是官方存储库：https : //github.com/AR-js-org/AR.js。如果您想访问旧的AR.js存储库，请访问：https : //github.com/jeromeetienne/AR.js。")]),a._v(" "),e("h2",{attrs:{id:"导入库"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#导入库"}},[a._v("#")]),a._v(" 导入库")]),a._v(" "),e("p",[a._v("版本3中的AR.js具有新的结构。")]),a._v(" "),e("p",[a._v("AR.js有两种不同的版本。它们都被维护。他们是独家的。")]),a._v(" "),e("p",[a._v("您要导入的文件取决于您要使用的功能以及要使用的渲染库（A-Frame或three.js）。")]),a._v(" "),e("p",[a._v("AR.js使用jsartoolkit5进行跟踪，但可以使用three.js或A-Frame显示增强的内容。")]),a._v(" "),e("p",[a._v("您可以使用"),e("code",[a._v("<script>")]),a._v("HTML上的标记，以您选择的一种版本导入AR.js。")]),a._v(" "),e("p",[a._v("具有图像跟踪+基于位置的AR的AR.js")]),a._v(" "),e("p",[a._v("导入AFRAME版本：")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js">\n')])])]),e("p",[a._v("导入three.js版本：")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('<script src="https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar-nft.js">\n')])])]),e("p",[a._v("具有标记跟踪+基于位置的AR的AR.js：")]),a._v(" "),e("p",[a._v("导入AFRAME版本：")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js">\n')])])]),e("p",[a._v("导入three.js版本：")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('<script src="https://raw.githack.com/AR-js-org/AR.js/master/three.js/build/ar.js">\n')])])]),e("p",[a._v("如果要导入特定版本，则可以轻松地替换master为version标签，例如：")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('<script src="https://raw.githack.com/AR-js-org/AR.js/3.0.0/aframe/build/aframe-ar-nft.js">\n')])])]),e("h2",{attrs:{id:"要求"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#要求"}},[a._v("#")]),a._v(" 要求")]),a._v(" "),e("p",[a._v("下面列出了一些要求和已知限制：")]),a._v(" "),e("p",[a._v("它适用于每一个使用webgl和webrtc的电话。\n基于标记的标记非常轻巧，而图像跟踪则消耗更多的CPU\n您无法在iOS上使用Chrome，因为iOS上的Chrome目前不支持摄像头访问\n在配备多相机的设备上，Chrome可能无法检测到正确的相机。如果发现AR.js在错误的相机上打开，请使用Firefox。有一个未解决的问题。\n要使用基于位置的功能，您的手机需要具有GPS传感器\n请仔细阅读AR.js弹出的任何建议（作为警报）以基于iOS的位置，因为iOS需要用户采取行动才能激活地理位置\n基于位置的功能仅在A框架上可用\n始终在https下部署\n由于主要浏览器的限制，只能在https网站上访问电话相机或相机GPS传感器。")]),a._v(" "),e("p",[a._v("您将看到的所有示例以及所有一般的AR.js Web应用程序都必须在服务器上运行。您可以使用本地服务器或在Web上部署静态Web应用程序。")]),a._v(" "),e("p",[a._v("因此，不要忘记总是在安全连接服务器或本地主机上运行示例。Github Pages是在https下拥有免费和实时网站的好方法。")]),a._v(" "),e("h2",{attrs:{id:"入门"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#入门"}},[a._v("#")]),a._v(" 入门")]),a._v(" "),e("p",[a._v("在这里，我们提供三个基本示例，每个AR功能一个。对于特定的文档，可以在顶部菜单中找到每个部分，或者可以单击以下链接：")]),a._v(" "),e("ul",[e("li",[a._v("图像跟踪文档")]),a._v(" "),e("li",[a._v("基于位置的文档")]),a._v(" "),e("li",[a._v("基于标记的文档")])]),a._v(" "),e("h3",{attrs:{id:"图像跟踪示例"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#图像跟踪示例"}},[a._v("#")]),a._v(" 图像跟踪示例")]),a._v(" "),e("p",[a._v("有一个Codepen供您尝试。您还可以在下面找到一个实时示例。")]),a._v(" "),e("p",[a._v("请按照以下简单步骤操作：")]),a._v(" "),e("ul",[e("li",[a._v("使用下面的代码创建一个新项目（或打开此实时示例并直接转到最后一步）")]),a._v(" "),e("li",[a._v("在服务器上运行")]),a._v(" "),e("li",[a._v("在手机上打开网站")]),a._v(" "),e("li",[a._v("扫描此图片以通过相机查看内容。")])]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('<script src="https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js"><\/script>\n<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"><\/script>\n\n<style>\n  .arjs-loader {\n    height: 100%;\n    width: 100%;\n    position: absolute;\n    top: 0;\n    left: 0;\n    background-color: rgba(0, 0, 0, 0.8);\n    z-index: 9999;\n    display: flex;\n    justify-content: center;\n    align-items: center;\n  }\n\n  .arjs-loader div {\n    text-align: center;\n    font-size: 1.25em;\n    color: white;\n  }\n</style>\n\n<body style="margin : 0px; overflow: hidden;">\n  \x3c!-- minimal loader shown until image descriptors are loaded --\x3e\n  <div class="arjs-loader">\n    <div>Loading, please wait...</div>\n  </div>\n  <a-scene\n    vr-mode-ui="enabled: false;"\n    renderer="logarithmicDepthBuffer: true;"\n    embedded\n    arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;"\n  >\n    \x3c!-- we use cors proxy to avoid cross-origin problems --\x3e\n    <a-nft\n      type="nft"\n      url="https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/trex-image/trex"\n      smooth="true"\n      smoothCount="10"\n      smoothTolerance=".01"\n      smoothThreshold="5"\n    >\n      <a-entity\n        gltf-model="https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf"\n        scale="5 5 5"\n        position="50 150 0"\n      >\n      </a-entity>\n    </a-nft>\n    <a-entity camera></a-entity>\n  </a-scene>\n</body>\n')])])]),e("h3",{attrs:{id:"基于位置的示例"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#基于位置的示例"}},[a._v("#")]),a._v(" 基于位置的示例")]),a._v(" "),e("p",[a._v("与此Codepen一起尝试。它检索您的位置并在您附近放置文字。")]),a._v(" "),e("p",[a._v("请按照以下简单步骤操作：")]),a._v(" "),e("ul",[e("li",[a._v("使用以下代码段创建一个新项目，add-your-latitude并add-your-longitude根据您- 的经度和纬度（不带）进行更改<>。")]),a._v(" "),e("li",[a._v("在服务器上运行")]),a._v(" "),e("li",[a._v("在手机上激活GPS并导航到示例URL")]),a._v(" "),e("li",[a._v("环视四周。即使您环顾四周并移动电话，您也应该会看到文字看着您，并显示在所需位置。")])]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <meta http-equiv="X-UA-Compatible" content="IE=edge" />\n    <title>GeoAR.js demo</title>\n    <script src="https://aframe.io/releases/1.0.4/aframe.min.js"><\/script>\n    <script src="https://unpkg.com/aframe-look-at-component@0.8.0/dist/aframe-look-at-component.min.js"><\/script>\n    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"><\/script>\n  </head>\n\n  <body style="margin: 0; overflow: hidden;">\n    <a-scene\n      vr-mode-ui="enabled: false"\n      embedded\n      arjs="sourceType: webcam; debugUIEnabled: false;"\n    >\n      <a-text\n        value="This content will always face you."\n        look-at="[gps-camera]"\n        scale="120 120 120"\n        gps-entity-place="latitude: <add-your-latitude>; longitude: <add-your-longitude>;"\n      ></a-text>\n      <a-camera gps-camera rotation-reader> </a-camera>\n    </a-scene>\n  </body>\n</html>\n')])])]),e("h3",{attrs:{id:"基于标记的示例"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#基于标记的示例"}},[a._v("#")]),a._v(" 基于标记的示例")]),a._v(" "),e("p",[a._v("请按照以下简单步骤操作：")]),a._v(" "),e("p",[a._v("使用下面的代码创建一个新项目（或打开此实时示例并直接转到最后一步）\n在服务器上运行\n在手机上打开网站\n扫描此图片以通过相机查看内容。")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v('<!DOCTYPE html>\n<html>\n  <script src="https://aframe.io/releases/1.0.4/aframe.min.js"><\/script>\n  \x3c!-- we import arjs version without NFT but with marker + location based support --\x3e\n  <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"><\/script>\n  <body style="margin : 0px; overflow: hidden;">\n    <a-scene embedded arjs>\n      <a-marker preset="hiro">\n        <a-entity\n          position="0 0 0"\n          scale="0.05 0.05 0.05"\n          gltf-model="https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf"\n        ></a-entity>\n      </a-marker>\n      <a-entity camera></a-entity>\n    </a-scene>\n  </body>\n</html>\n')])])]),e("h3",{attrs:{id:"更进一步的内容"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#更进一步的内容"}},[a._v("#")]),a._v(" 更进一步的内容")]),a._v(" "),e("p",[a._v("AR.js提供了两种与A-Frame进行网页交互的方法：直接与AR内容进行交互以及Overlayed DOM交互。")]),a._v(" "),e("p",[a._v("另外，在每个AR.js Web应用程序的生命周期中都会触发几个自定义事件。")]),a._v(" "),e("p",[a._v("您可以在“ UI和事件”部分了解有关这些方面的更多信息。")]),a._v(" "),e("h3",{attrs:{id:"ar-js架构"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ar-js架构"}},[a._v("#")]),a._v(" AR.js架构")]),a._v(" "),e("p",[a._v("AR.js使用jsartoolkit5进行跟踪，但可以使用three.js或A-Frame显示增强的内容。")]),a._v(" "),e("p",[a._v("three.js 文件夹包含")]),a._v(" "),e("ul",[e("li",[a._v("AR.js核心，基于标记和图像跟踪的源代码")]),a._v(" "),e("li",[a._v("基于AR.js three.js的示例")]),a._v(" "),e("li",[a._v("为Three.js构建基于AR.js")]),a._v(" "),e("li",[a._v("供应商的东西（jsartoolkit5）")]),a._v(" "),e("li",[a._v("工人（用于图像跟踪）。\n当您找到-nft后缀结尾的文件时，它们仅受图像跟踪版本的限制。")])]),a._v(" "),e("p",[a._v("A.Frame版本的AR.js使用three.js部分作为其核心。AR.js上的A-Frame代码只是用于使用HTML用自定义组件编写AR的包装器。")]),a._v(" "),e("p",[a._v("aframe 文件夹包含")]),a._v(" "),e("ul",[e("li",[a._v("AR.js A框架的源代码（又称为基于标记的图像跟踪组件的包装器）")]),a._v(" "),e("li",[a._v("基于位置的源代码")]),a._v(" "),e("li",[a._v("为基于A-Frame AR.js的构建")]),a._v(" "),e("li",[a._v("A-Frame AR.js的示例。")])])])}),[],!1,null,null,null);t.default=r.exports}}]);